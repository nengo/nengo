{
 "metadata": {
  "name": "",
  "signature": "sha256:9fc9897805f7e8c2cb0f6bb393dc4b63899faa92f7e8b2172e1f7880095fe6c5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Nengo Example: Learning a communication channel\n",
      "\n",
      "Normally, if you have a function you would like to compute\n",
      "across a connection, you would specify it with `function=my_func`\n",
      "in the `Connection` constructor.\n",
      "However, it is also possible to use error-driven learning\n",
      "to learn to compute a function online."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 1: Create the model without learning\n",
      "\n",
      "We'll start by creating a connection between two populations\n",
      "that intially computes a very weird function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "import nengo\n",
      "from nengo.processes import WhiteNoise\n",
      "%load_ext nengo.ipynb\n"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = nengo.Network()\n",
      "with model:\n",
      "    inp = nengo.Node(WhiteNoise(60, high=5).f(d=2))\n",
      "    pre = nengo.Ensemble(60, dimensions=2)\n",
      "    nengo.Connection(inp, pre)\n",
      "    post = nengo.Ensemble(60, dimensions=2)\n",
      "    conn = nengo.Connection(pre, post, function=lambda x: np.random.random(2))\n",
      "    inp_p = nengo.Probe(inp)\n",
      "    pre_p = nengo.Probe(pre, synapse=0.01)\n",
      "    post_p = nengo.Probe(post, synapse=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If we run this model as is, we can see that the connection\n",
      "from `pre` to `post` doesn't compute much of value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(10.0)"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(12, 8))\n",
      "plt.subplot(2, 1, 1)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[0], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[0], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[0], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 1\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(2, 1, 2)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[1], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[1], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[1], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 2\")\n",
      "plt.legend(loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2: Add in learning\n",
      "\n",
      "If we can generate an error signal, then we can minimize\n",
      "that error signal using the `nengo.PES` learning rule.\n",
      "Since it's a communication channel, we know the value that we want,\n",
      "so we can compute the error with another ensemble."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    error = nengo.Ensemble(60, dimensions=2)\n",
      "    error_p = nengo.Probe(error, synapse=0.03)\n",
      "    # Error = pre - post\n",
      "    nengo.Connection(pre, error)\n",
      "    nengo.Connection(post, error, transform=-1)\n",
      "    # Modulatory connections don't impart current\n",
      "    error_conn = nengo.Connection(error, post, modulatory=True)\n",
      "    # Add the learning rule to the connection\n",
      "    conn.learning_rule_type = nengo.PES(error_conn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we can see the `post` population gradually learn to compute\n",
      "the communication channel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(10.0)"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(12, 12))\n",
      "plt.subplot(3, 1, 1)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[0], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[0], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[0], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 1\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 2)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[1], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[1], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[1], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 2\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 3)\n",
      "plt.plot(sim.trange(), sim.data[error_p], c='b')\n",
      "plt.ylim(-1, 1)\n",
      "plt.legend((\"Error[0]\", \"Error[1]\"), loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Does it generalize?\n",
      "\n",
      "If the learning rule is always working, the error will continue to be minimized.\n",
      "But have we actually generalized to be able to compute the communication channel\n",
      "without this error signal?\n",
      "Let's inhibit the `error` population after 10 seconds."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def inhibit(t):\n",
      "    return 2.0 if t > 10.0 else 0.0\n",
      "with model:\n",
      "    inhib = nengo.Node(inhibit)\n",
      "    nengo.Connection(inhib, error.neurons, transform=[[-1]] * error.n_neurons)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(16.0)"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(12, 12))\n",
      "plt.subplot(3, 1, 1)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[0], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[0], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[0], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 1\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 2)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[1], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[1], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[1], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 2\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 3)\n",
      "plt.plot(sim.trange(), sim.data[error_p], c='b')\n",
      "plt.ylim(-1, 1)\n",
      "plt.legend((\"Error[0]\", \"Error[1]\"), loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# How does this work?\n",
      "\n",
      "The `nengo.PES` learning rule minimizes the same error online\n",
      "as the decoder solvers minimize with offline optimization.\n",
      "\n",
      "Let $\\mathbf{E}$ be an error signal.\n",
      "In the communication channel case, the error signal\n",
      "$\\mathbf{E} = \\mathbf{\\hat{x}} - \\mathbf{x}$;\n",
      "in other words, it is the difference between\n",
      "the decoded estimate of `post`, $\\mathbf{\\hat{x}}$,\n",
      "and the decoded estimate of `pre`, $\\mathbf{x}$.\n",
      "\n",
      "The PES learning rule on decoders is\n",
      "$$\\Delta \\mathbf{d_i} = \\kappa \\mathbf{E} a_i,$$\n",
      "where $\\mathbf{d_i}$ are the decoders being learned,\n",
      "$\\kappa$ is a scalar learning rate and $a_i$ is the\n",
      "filtered activity of the `pre` population.\n",
      "\n",
      "However, many synaptic plasticity experiments\n",
      "result in learning rules that explain how\n",
      "individual connection weights change.\n",
      "We can multiply both sides of the equation\n",
      "by the encoders of the `post` population,\n",
      "$\\mathbf{e_j}$, and the gain of the `post`\n",
      "population $\\alpha_j$, as we do in\n",
      "Principle 2 of the NEF.\n",
      "This results in the learning rule\n",
      "\\begin{align}\n",
      "  \\Delta \\mathbf{d_i} \\cdot \\mathbf{e_j} \\alpha_j &= \\kappa \\alpha_j \\mathbf{e_j} \\cdot \\mathbf{E} a_i \\\\\n",
      "  \\Delta \\omega_{ij} &= \\kappa \\alpha_j \\mathbf{e_j} \\cdot \\mathbf{E} a_i,\n",
      "\\end{align}\n",
      "where $\\omega_{ij}$ is the connection between `pre` neuron $i$ and `post` neuron $j$.\n",
      "\n",
      "The weight-based version of PES can be easily combined with\n",
      "learning rules that describe synaptic plasticity experiments.\n",
      "In Nengo, the `Connection.learning_rule_type` parameter accepts\n",
      "a list of learning rules.\n",
      "See [Bekolay et al., 2013](http://compneuro.uwaterloo.ca/publications/bekolay2013.html)\n",
      "for details on what happens when the PES learning rule is\n",
      "combined with an unsupervised learning rule."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# How do the decoders / weights change?\n",
      "\n",
      "The equations above describe\n",
      "how the decoders and connection weights change\n",
      "as a result of the PES rule.\n",
      "But are there any general principles\n",
      "that we can say about how the rule\n",
      "modifies decoders and connection weights?\n",
      "Determining this requires analyzing\n",
      "the decoders and connection weights\n",
      "as they change over the course of a simulation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    dec_p = nengo.Probe(conn, 'decoders', synapse=0.01, sample_every=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(4.0)"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(12, 12))\n",
      "plt.subplot(3, 1, 1)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[0], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[0], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[0], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 1\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 2)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[1], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[1], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[1], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 2\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 3)\n",
      "plt.plot(sim.trange(dt=0.01), sim.data[dec_p][..., 10])\n",
      "plt.ylabel(\"Decoding weight\")\n",
      "plt.legend((\"Decoder 10[0]\", \"Decoder 10[1]\"), loc='best');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from nengo.solvers import LstsqL2\n",
      "with model:\n",
      "    # Change the connection to use connection weights instead of decoders\n",
      "    conn.solver = LstsqL2(weights=True)\n",
      "    trans_p = nengo.Probe(conn, 'transform', synapse=0.01, sample_every=0.01)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sim = nengo.Simulator(model)\n",
      "sim.run(4.0)"
     ],
     "language": "python",
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.figure(figsize=(12, 12))\n",
      "plt.subplot(3, 1, 1)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[0], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[0], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[0], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 1\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 2)\n",
      "plt.plot(sim.trange(), sim.data[inp_p].T[1], c='k', label='Input')\n",
      "plt.plot(sim.trange(), sim.data[pre_p].T[1], c='b', label='Pre')\n",
      "plt.plot(sim.trange(), sim.data[post_p].T[1], c='r', label='Post')\n",
      "plt.ylabel(\"Dimension 2\")\n",
      "plt.legend(loc='best')\n",
      "plt.subplot(3, 1, 3)\n",
      "plt.plot(sim.trange(dt=0.01), sim.data[trans_p][..., 10])\n",
      "plt.ylabel(\"Connection weight\");"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We haven't yet discovered if there\n",
      "are any general principles governing\n",
      "how the decoders and connection weights change.\n",
      "But, it's interesting to see the general trends;\n",
      "often a few strong connection weights will\n",
      "dominate the others,\n",
      "while decoding weights tend to\n",
      "change or not change together."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}
