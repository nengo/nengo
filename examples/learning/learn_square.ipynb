{
 "metadata": {
  "name": "learn_square",
  "signature": "sha256:9b43de8a8e25628b30a324d31dd7546a808b0cda275f3b7c4e5747fe49eb9b66"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Nengo Example: Learning to square the input"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This demo shows you how to construct a network containing an ensemble which learns how to decode the square of its value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "import nengo\n",
      "%load_ext nengo.ipynb"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 1: Create the Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This network consists of an ensemble **`A`** which represents the input, an ensemble **`A_squared`** which learns to represent the square, and an ensemble **`error`** which represents the error between `A_squared` and the actual square."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = nengo.Network()\n",
      "with model:\n",
      "    # Create the ensemble to represent the input, the input squared (learned), and the error\n",
      "    A = nengo.Ensemble(100, dimensions=1)\n",
      "    A_squared = nengo.Ensemble(100, dimensions=1)\n",
      "    error = nengo.Ensemble(100, dimensions=1)\n",
      "    \n",
      "    # Connect A and A_squared with a communication channel\n",
      "    conn = nengo.Connection(A, A_squared)\n",
      "    \n",
      "    # Apply the PES learning rule to conn\n",
      "    conn.learning_rule_type = nengo.PES(learning_rate=3e-4)\n",
      "    \n",
      "    # Provide an error signal to the learning rule\n",
      "    nengo.Connection(error, conn.learning_rule)\n",
      "\n",
      "    # Compute the error signal (error = actual - target)\n",
      "    nengo.Connection(A_squared, error)\n",
      "    \n",
      "    # Subtract the target (this would normally come from some external system)\n",
      "    nengo.Connection(A, error, function=lambda x: x**2, transform=-1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 2: Provide Input to the Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A single input signal (a step function) will be used to drive the neural activity in ensemble A. An additonal node will inhibit the error signal after 15 seconds, to test the learning at the end."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    # Create an input node that steps between -1 and 1\n",
      "    input_node = nengo.Node(output=lambda t: int(6*t/5)/3.0 % 2 - 1)\n",
      "    \n",
      "    # Connect the input node to ensemble A\n",
      "    nengo.Connection(input_node, A)\n",
      "    \n",
      "    # Shut off learning by inhibiting the error population\n",
      "    stop_learning = nengo.Node(output=lambda t: t >= 15)\n",
      "    nengo.Connection(stop_learning, error.neurons, transform=-20*np.ones((error.n_neurons, 1)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 3: Probe the Output"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's collect output data from each ensemble and output."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with model:\n",
      "    input_node_probe = nengo.Probe(input_node)\n",
      "    A_probe = nengo.Probe(A, synapse=0.01)\n",
      "    A_squared_probe = nengo.Probe(A_squared, synapse=0.01)\n",
      "    error_probe = nengo.Probe(error, synapse=0.01)\n",
      "    learn_probe = nengo.Probe(stop_learning, synapse=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Step 4: Run the Model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Create the simulator\n",
      "sim = nengo.Simulator(model)\n",
      "sim.run(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Plot the input signal\n",
      "plt.figure(figsize=(9, 9))\n",
      "plt.subplot(3, 1, 1)\n",
      "plt.plot(sim.trange(), sim.data[input_node_probe], label='Input', color='k', linewidth=2.0)\n",
      "plt.plot(sim.trange(), sim.data[learn_probe], label='Stop learning?', color='r', linewidth=2.0)\n",
      "plt.legend(loc='lower right')\n",
      "plt.ylim(-1.2, 1.2)\n",
      "\n",
      "plt.subplot(3, 1, 2)\n",
      "plt.plot(sim.trange(), sim.data[input_node_probe] ** 2, label='Squared Input', linewidth=2.0)\n",
      "plt.plot(sim.trange(), sim.data[A_squared_probe], label='Decoded Ensemble $A^2$')\n",
      "plt.legend(loc='lower right')\n",
      "plt.ylim(-1.2, 1.2)\n",
      "\n",
      "plt.subplot(3, 1, 3)\n",
      "plt.plot(sim.trange(), sim.data[A_squared_probe] - sim.data[input_node_probe]**2, label='Error')\n",
      "plt.legend(loc='lower right')\n",
      "plt.tight_layout();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that during the first three periods, the decoders quickly adjust to drive the error to zero. When learning is turned off for the fourth period, the error stays closer to zero, demonstrating that the learning has persisted in the connection."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}